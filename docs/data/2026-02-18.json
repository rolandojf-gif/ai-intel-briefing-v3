{
  "date": "2026-02-18",
  "score_avg": 69.67,
  "primary_dist": {
    "infra": 3,
    "models": 9,
    "geopol": 1,
    "misc": 1,
    "invest": 1
  },
  "top_entities": [
    {
      "entity": "NVIDIA",
      "count": 7
    },
    {
      "entity": "OpenAI",
      "count": 3
    },
    {
      "entity": "Google DeepMind",
      "count": 2
    },
    {
      "entity": "Hopper",
      "count": 1
    },
    {
      "entity": "Peter Steinberger",
      "count": 1
    }
  ],
  "briefing": {
    "signals": [
      "OpenAI consolida su era agentica con GPT-5.3 Codex y la contratacion de talento clave para agentes personales.",
      "Reino Unido lidera la soberania IA europea con el supercomputador Isambard-AI y modelos regionales en Nemotron.",
      "La IA Fisica emerge como el nuevo paradigma dominante conectando modelos generativos con robotica y vehiculos.",
      "La infraestructura NVIDIA GB200 se valida como el estandar critico para el despliegue de modelos de frontera.",
      "Nuevos benchmarks como ResearchGym y FACTS elevan la exigencia en autonomia de investigacion y veracidad de datos."
    ],
    "risks": [
      "Dependencia extrema de la arquitectura Blackwell/GB200 de NVIDIA para la viabilidad de modelos de proxima generacion.",
      "Dificultad en garantizar seguridad estricta en Reinforcement Learning para aplicaciones fisicas criticas.",
      "Saturacion de benchmarks que podria derivar en sobreajuste de modelos a metricas especificas en lugar de utilidad."
    ],
    "watch": [
      "Despliegue operativo de agentes personales de OpenAI bajo el liderazgo de Peter Steinberger.",
      "Integracion de arquitecturas unificadas end-to-end en el ecosistema de vehiculos autonomos.",
      "Resultados de la implementacion de modelos soberanos en lenguas minoritarias como el gales y gaelico."
    ],
    "entities_top": [
      "NVIDIA",
      "OpenAI",
      "Google DeepMind"
    ]
  },
  "items": [
    {
      "title": "As AI Grows More Complex, Model Builders Rely on NVIDIA",
      "link": "https://blogs.nvidia.com/blog/leading-models-nvidia/",
      "published": "2025-12-11T19:19:57+00:00",
      "summary": "Unveiling what it describes as the most capable model series yet for professional knowledge work, OpenAI launched GPT-5.2 in December. The model was trained and deployed on NVIDIA infrastructure, including NVIDIA Hopper and GB200 NVL72 systems. GPT-5.3 Codex — the first OpenAI agentic coding model to help build itself — was released in February and Read Article",
      "source": "NVIDIA Blog (AI)",
      "feed_tags": [
        "infra",
        "chips"
      ],
      "score": 95,
      "primary": "infra",
      "tags": [
        "gpu",
        "training",
        "supercomputing",
        "partnership"
      ],
      "url": "https://blogs.nvidia.com/blog/leading-models-nvidia/",
      "_rid": 2,
      "why": "Confirma que GPT-5.2 y 5.3 se entrenaron en sistemas GB200, validando el dominio absoluto de NVIDIA en la computacion de frontera.",
      "entities": [
        "NVIDIA",
        "OpenAI",
        "Hopper"
      ]
    },
    {
      "title": "You can just build things. Peter Steinberger is joining OpenAI to drive the next generation of personal agents. He is a genius with a lot of amazing ideas ab...",
      "summary": "You can just build things. Peter Steinberger is joining OpenAI to drive the next generation of personal agents. He is a genius with a lot of amazing ideas about the future of very smart agents interacting with each other to do very useful things for people. We expect this will quickly become core to our Very excited about the \"First Proof\" challenge. I believe novel frontier research is perhaps the most important way to evaluate capabilities of the next generation of AI models. We have run our internal model with limited human supervision on the ten proposed problems. The",
      "link": "https://x.com/OpenAI?post=a17b85292233",
      "published": "Wed, 18 Feb 2026 07:10:41 GMT",
      "source": "X @OpenAI",
      "feed_tags": [
        "x",
        "models",
        "products"
      ],
      "score": 88,
      "primary": "models",
      "tags": [
        "agents",
        "hiring",
        "product-strategy",
        "software"
      ],
      "url": "https://x.com/OpenAI?post=a17b85292233",
      "_rid": 11,
      "why": "La incorporacion de Peter Steinberger a OpenAI senala un giro estrategico agresivo hacia agentes personales interactivos.",
      "entities": [
        "OpenAI",
        "Peter Steinberger"
      ]
    },
    {
      "title": "ResearchGym: Evaluating Language Model Agents on Real-World AI Research",
      "link": "https://arxiv.org/abs/2602.15112",
      "published": "2026-02-18T05:00:00+00:00",
      "summary": "arXiv:2602.15112v1 Announce Type: new Abstract: We introduce ResearchGym, a benchmark and execution environment for evaluating AI agents on end-to-end research. To instantiate this, we repurpose five oral and spotlight papers from ICML, ICLR, and ACL. From each paper's repository, we preserve the datasets, evaluation harness, and baseline implementations but withhold the paper's proposed method. This results in five containerized task environments comprising 39 sub-tasks in total. Within each environment, agents must propose novel hypotheses, run experiments, and attempt to surpass strong human baselines on the paper's metrics. In a controlled evaluation of an agent powered by GPT-5, we observe a sharp capability--reliability gap. The agent improves over the provided baselines from the repository in just 1 of 15 evaluations (6.7%) by 11.5%, and completes only 26.5% of sub-tasks on average. We identify recurring long-horizon failure modes, including impatience, poor time and resource management, overconfidence in weak hypotheses, difficulty coordinating parallel experiments, and hard limits from context length. Yet in a single run, the agent surpasses the solution of an ICML 2025 Spotlight task, indicating that frontier agents can occasionally reach state-of-the-art performance, but do so unreliably. We additionally evaluate proprietary agent scaffolds including Claude Code (Opus-4.5) and Codex (GPT-5.2) which display a similar gap. ResearchGym provides infrastructure for systematic evaluation and analysis of autonomous agents on closed-loop research.",
      "source": "arXiv cs.AI",
      "feed_tags": [
        "papers",
        "models"
      ],
      "score": 85,
      "primary": "models",
      "tags": [
        "agents",
        "benchmarking",
        "research",
        "automation"
      ],
      "url": "https://arxiv.org/abs/2602.15112",
      "_rid": 1,
      "why": "ResearchGym permite evaluar agentes en tareas de investigacion real, marcando un hito en la automatizacion del metodo cientifico.",
      "entities": [
        "OpenAI",
        "GPT-5"
      ]
    },
    {
      "title": "Isambard-AI, the UK’s Most Powerful AI Supercomputer, Goes Live",
      "link": "https://blogs.nvidia.com/blog/isambard-ai/",
      "published": "2025-07-17T17:00:50+00:00",
      "summary": "The University of Bristol’s Isambard-AI, powered by NVIDIA Grace Hopper Superchips, delivers 21 exaflops of AI performance, making it the fastest system in the U.K. and among the most energy-efficient globally.",
      "source": "NVIDIA Blog (AI)",
      "feed_tags": [
        "infra",
        "chips"
      ],
      "score": 82,
      "primary": "infra",
      "tags": [
        "supercomputer",
        "hpc",
        "uk",
        "energy-efficiency"
      ],
      "url": "https://blogs.nvidia.com/blog/isambard-ai/",
      "_rid": 5,
      "why": "La activacion de Isambard-AI posiciona al Reino Unido con 21 exaflops de rendimiento para investigacion de vanguardia.",
      "entities": [
        "NVIDIA",
        "University of Bristol"
      ]
    },
    {
      "title": "NVIDIA Releases New AI Models and Developer Tools to Advance Autonomous Vehicle Ecosystem",
      "link": "https://blogs.nvidia.com/blog/autonomous-vehicle-ecosystem-ai-models-developer-tools/",
      "published": "2025-06-11T10:55:36+00:00",
      "summary": "Autonomous vehicle (AV) stacks are evolving from many distinct models to a unified, end-to-end architecture that executes driving actions directly from sensor data. This transition to using larger models is drastically increasing the demand for high-quality, physically based sensor data for training, testing and validation. To help accelerate the development of next-generation AV architectures, NVIDIA Read Article",
      "source": "NVIDIA Blog (AI)",
      "feed_tags": [
        "infra",
        "chips"
      ],
      "score": 78,
      "primary": "models",
      "tags": [
        "autonomous-vehicles",
        "simulation",
        "sensors",
        "training"
      ],
      "url": "https://blogs.nvidia.com/blog/autonomous-vehicle-ecosystem-ai-models-developer-tools/",
      "_rid": 10,
      "why": "La transicion a arquitecturas unificadas en vehiculos autonomos demanda modelos mas grandes y datos simulados de alta fidelidad.",
      "entities": [
        "NVIDIA"
      ]
    },
    {
      "title": "NVIDIA Research Shapes Physical AI",
      "link": "https://blogs.nvidia.com/blog/physical-ai-research-siggraph-2025/",
      "published": "2025-08-11T15:00:38+00:00",
      "summary": "AI and graphics research breakthroughs in neural rendering, 3D generation and world simulation power robotics, autonomous vehicles and content creation.",
      "source": "NVIDIA Blog (AI)",
      "feed_tags": [
        "infra",
        "chips"
      ],
      "score": 75,
      "primary": "models",
      "tags": [
        "robotics",
        "simulation",
        "rendering",
        "physical-ai"
      ],
      "url": "https://blogs.nvidia.com/blog/physical-ai-research-siggraph-2025/",
      "_rid": 3,
      "why": "NVIDIA Research impulsa la IA fisica para cerrar la brecha entre modelos digitales y el mundo real en robotica y conduccion.",
      "entities": [
        "NVIDIA"
      ]
    },
    {
      "title": "Improved Gemini audio models for powerful voice experiences",
      "link": "https://deepmind.google/blog/improved-gemini-audio-models-for-powerful-voice-experiences/",
      "published": "2025-12-12T17:50:50+00:00",
      "summary": "",
      "source": "DeepMind Blog",
      "feed_tags": [
        "labs",
        "models"
      ],
      "score": 75,
      "primary": "models",
      "tags": [
        "audio",
        "voice",
        "multimodal",
        "gemini"
      ],
      "url": "https://deepmind.google/blog/improved-gemini-audio-models-for-powerful-voice-experiences/",
      "_rid": 14,
      "why": "DeepMind mejora Gemini para experiencias de voz, intensificando la competencia por interfaces naturales de audio multimodales.",
      "entities": [
        "Google DeepMind",
        "Gemini"
      ]
    },
    {
      "title": "Quote Arena.ai @arena Feb 7 The new @xAI Grok-Imagine-Image model is a Pareto-optimal model in Image Arena: The Pareto frontier tells us which model has the ...",
      "summary": "Quote Arena.ai @arena Feb 7 The new @xAI Grok-Imagine-Image model is a Pareto-optimal model in Image Arena: The Pareto frontier tells us which model has the highest Arena score at each price point. @xAi’s latest models have improved the frontier, giving optimal performance in the mid-price tier. For a wide  x.com/arena/status/2… [Show more](https://x.com/arena/status/2020215931646120004)",
      "link": "https://x.com/xai?post=bdc628325476",
      "published": null,
      "source": "X @xai",
      "feed_tags": [
        "x",
        "models"
      ],
      "score": 72,
      "primary": "models",
      "tags": [
        "multimodal",
        "vision-models",
        "benchmarks",
        "efficiency"
      ],
      "url": "https://x.com/xai?post=bdc628325476",
      "_rid": 12,
      "why": "Grok-Imagine-Image alcanza la frontera de Pareto optimizando el balance entre rendimiento visual y coste operativo.",
      "entities": [
        "xAI"
      ]
    },
    {
      "title": "FACTS Benchmark Suite: Systematically evaluating the factuality of large language models",
      "link": "https://deepmind.google/blog/facts-benchmark-suite-systematically-evaluating-the-factuality-of-large-language-models/",
      "published": "2025-12-09T11:29:03+00:00",
      "summary": "Systematically evaluating the factuality of large language models with the FACTS Benchmark Suite.",
      "source": "DeepMind Blog",
      "feed_tags": [
        "labs",
        "models"
      ],
      "score": 70,
      "primary": "models",
      "tags": [
        "hallucination",
        "factuality",
        "benchmarking",
        "llm"
      ],
      "url": "https://deepmind.google/blog/facts-benchmark-suite-systematically-evaluating-the-factuality-of-large-language-models/",
      "_rid": 15,
      "why": "FACTS Benchmark sistematiza la evaluacion de veracidad en LLMs, atacando el problema critico de las alucinaciones en modelos.",
      "entities": [
        "Google DeepMind"
      ]
    },
    {
      "title": "Reaching Across the Isles: UK-LLM Brings AI to UK Languages With NVIDIA Nemotron",
      "link": "https://blogs.nvidia.com/blog/uk-llm-nemotron/",
      "published": "2025-09-14T01:00:21+00:00",
      "summary": "Celtic languages — including Cornish, Irish, Scottish Gaelic and Welsh — are the U.K.’s oldest living languages. To empower their speakers, the UK-LLM sovereign AI initiative is building an AI model based on NVIDIA Nemotron that can reason in both English and Welsh, a language spoken by about 850,000 people in Wales today. Enabling high-quality Read Article",
      "source": "NVIDIA Blog (AI)",
      "feed_tags": [
        "infra",
        "chips"
      ],
      "score": 65,
      "primary": "geopol",
      "tags": [
        "sovereign-ai",
        "llm",
        "regional",
        "nemotron"
      ],
      "url": "https://blogs.nvidia.com/blog/uk-llm-nemotron/",
      "_rid": 4,
      "why": "El proyecto UK-LLM demuestra la viabilidad de modelos soberanos para preservar lenguas regionales usando infraestructura global.",
      "entities": [
        "NVIDIA",
        "UK-LLM"
      ]
    },
    {
      "title": "Attention-gated U-Net model for semantic segmentation of brain tumors and feature extraction for survival prognosis",
      "link": "https://arxiv.org/abs/2602.15067",
      "published": "2026-02-18T05:00:00+00:00",
      "summary": "arXiv:2602.15067v1 Announce Type: new Abstract: Gliomas, among the most common primary brain tumors, vary widely in aggressiveness, prognosis, and histology, making treatment challenging due to complex and time-intensive surgical interventions. This study presents an Attention-Gated Recurrent Residual U-Net (R2U-Net) based Triplanar (2.5D) model for improved brain tumor segmentation. The proposed model enhances feature representation and segmentation accuracy by integrating residual, recurrent, and triplanar architectures while maintaining computational efficiency, potentially aiding in better treatment planning. The proposed method achieves a Dice Similarity Score (DSC) of 0.900 for Whole Tumor (WT) segmentation on the BraTS2021 validation set, demonstrating performance comparable to leading models. Additionally, the triplanar network extracts 64 features per planar model for survival days prediction, which are reduced to 28 using an Artificial Neural Network (ANN). This approach achieves an accuracy of 45.71%, a Mean Squared Error (MSE) of 108,318.128, and a Spearman Rank Correlation Coefficient (SRC) of 0.338 on the test dataset.",
      "source": "arXiv cs.AI",
      "feed_tags": [
        "papers",
        "models"
      ],
      "score": 65,
      "primary": "models",
      "tags": [
        "healthcare",
        "computer-vision",
        "oncology",
        "diagnostics"
      ],
      "url": "https://arxiv.org/abs/2602.15067",
      "_rid": 13,
      "why": "Modelos R2U-Net mejoran la segmentacion de tumores cerebrales, demostrando el impacto directo de la vision por IA en medicina.",
      "entities": [
        "Attention",
        "Net"
      ]
    },
    {
      "title": "Ceva IP: Powering the Era of Physical AI",
      "link": "https://semiwiki.com/ip/ceva/366114-ceva-ip-powering-the-era-of-physical-ai/",
      "published": "2026-02-17T22:00:13+00:00",
      "summary": "Artificial intelligence is rapidly moving beyond the digital domain and into the physical world. From autonomous robots and smart factories to intelligent vehicles and connected consumer devices, AI systems are increasingly expected to perceive their surroundings, make real-time decisions, and act on them instantly. This&#8230; Read More The post Ceva IP: Powering the Era of Physical AI appeared first on SemiWiki .",
      "source": "SemiWiki",
      "feed_tags": [
        "infra",
        "chips"
      ],
      "score": 60,
      "primary": "infra",
      "tags": [
        "edge-ai",
        "robotics",
        "semiconductors",
        "ip"
      ],
      "url": "https://semiwiki.com/ip/ceva/366114-ceva-ip-powering-the-era-of-physical-ai/",
      "_rid": 7,
      "why": "Ceva IP expande la IA fisica al borde con soluciones para percepcion y toma de decisiones en tiempo real en dispositivos IoT.",
      "entities": [
        "Ceva"
      ]
    },
    {
      "title": "Near-Optimal Sample Complexity for Online Constrained MDPs",
      "link": "https://arxiv.org/abs/2602.15076",
      "published": "2026-02-18T05:00:00+00:00",
      "summary": "arXiv:2602.15076v1 Announce Type: new Abstract: Safety is a fundamental challenge in reinforcement learning (RL), particularly in real-world applications such as autonomous driving, robotics, and healthcare. To address this, Constrained Markov Decision Processes (CMDPs) are commonly used to enforce safety constraints while optimizing performance. However, existing methods often suffer from significant safety violations or require a high sample complexity to generate near-optimal policies. We address two settings: relaxed feasibility, where small violations are allowed, and strict feasibility, where no violation is allowed. We propose a model-based primal-dual algorithm that balances regret and bounded constraint violations, drawing on techniques from online RL and constrained optimization. For relaxed feasibility, we prove that our algorithm returns an $\\varepsilon$-optimal policy with $\\varepsilon$-bounded violation with arbitrarily high probability, requiring $\\tilde{O}\\left(\\frac{SAH^3}{\\varepsilon^2}\\right)$ learning episodes, matching the lower bound for unconstrained MDPs. For strict feasibility, we prove that our algorithm returns an $\\varepsilon$-optimal policy with zero violation with arbitrarily high probability, requiring $\\tilde{O}\\left(\\frac{SAH^5}{\\varepsilon^2\\zeta^2}\\right)$ learning episodes, where $\\zeta$ is the problem-dependent Slater constant characterizing the size of the feasible region. This result matches the lower bound for learning CMDPs with access to a generative model. Our results demonstrate that learning CMDPs in an online setting is as easy as learning with a generative model and is no more challenging than learning unconstrained MDPs when small violations are allowed.",
      "source": "arXiv cs.LG",
      "feed_tags": [
        "papers",
        "models"
      ],
      "score": 55,
      "primary": "models",
      "tags": [
        "rl",
        "safety",
        "robotics",
        "algorithms"
      ],
      "url": "https://arxiv.org/abs/2602.15076",
      "_rid": 8,
      "why": "Nuevos algoritmos para procesos de decision restringidos buscan garantizar seguridad en aplicaciones criticas de conduccion.",
      "entities": [
        "Near",
        "Optimal Sample Complexity",
        "Online Constrained"
      ]
    },
    {
      "title": "Innovation to Impact: How NVIDIA Research Fuels Transformative Work in AI, Graphics and Beyond",
      "link": "https://blogs.nvidia.com/blog/nvidia-research-ai-graphics/",
      "published": "2025-03-20T00:00:24+00:00",
      "summary": "The roots of many of NVIDIA’s landmark innovations — the foundational technology that powers AI, accelerated computing, real-time ray tracing and seamlessly connected data centers — can be found in the company’s research organization, a global team of around 400 experts in fields including computer architecture, generative AI, graphics and robotics. Established in 2006 and Read Article",
      "source": "NVIDIA Blog (AI)",
      "feed_tags": [
        "infra",
        "chips"
      ],
      "score": 50,
      "primary": "misc",
      "tags": [
        "innovation",
        "corporate",
        "research",
        "graphics"
      ],
      "url": "https://blogs.nvidia.com/blog/nvidia-research-ai-graphics/",
      "_rid": 6,
      "why": "NVIDIA destaca su trayectoria de 20 anos en investigacion como motor fundamental de su dominio tecnologico actual.",
      "entities": [
        "NVIDIA"
      ]
    },
    {
      "title": "Applications Now Open for $60,000 NVIDIA Graduate Fellowship Awards",
      "link": "https://blogs.nvidia.com/blog/applications-open-graduate-fellowship-awards-2025/",
      "published": "2025-08-13T15:00:02+00:00",
      "summary": "Bringing together the world’s brightest minds and the latest accelerated computing technology leads to powerful breakthroughs that help tackle some of the biggest research problems. To foster such innovation, the NVIDIA Graduate Fellowship Program provides grants, mentors and technical support to doctoral students doing outstanding research relevant to NVIDIA technologies. The program, in its 25th Read Article",
      "source": "NVIDIA Blog (AI)",
      "feed_tags": [
        "infra",
        "chips"
      ],
      "score": 30,
      "primary": "invest",
      "tags": [
        "talent",
        "fellowship",
        "education",
        "grants"
      ],
      "url": "https://blogs.nvidia.com/blog/applications-open-graduate-fellowship-awards-2025/",
      "_rid": 9,
      "why": "NVIDIA mantiene su inversion en talento doctoral para asegurar el pipeline de innovacion tecnologica a largo plazo.",
      "entities": [
        "NVIDIA"
      ]
    }
  ]
}