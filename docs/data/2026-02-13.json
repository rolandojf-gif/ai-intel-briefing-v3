{
  "date": "2026-02-13",
  "score_avg": 84.1,
  "primary_dist": {
    "models": 8,
    "infra": 6,
    "geopol": 1
  },
  "top_entities": [
    [
      "NVIDIA",
      6
    ],
    [
      "Jensen Huang",
      2
    ],
    [
      "Google DeepMind",
      2
    ],
    [
      "OpenAI",
      1
    ],
    [
      "TSMC",
      1
    ]
  ],
  "briefing": {
    "signals": [
      "GPT-5.2/5.3 confirman el uso masivo de Blackwell GB200 para agentes de codificación que se construyen a sí mismos.",
      "La competencia en fundición para 2026 entre TSMC, Intel y Samsung será el pilar de la próxima generación de silicio.",
      "La memoria HBM y nuevas arquitecturas de RAM desplazan al cómputo puro como principal cuello de botella de la IA.",
      "Soberanía tecnológica en Reino Unido se materializa con Isambard-AI y modelos LLM en lenguajes nativos celtas.",
      "La IA física y simulación end-to-end están reemplazando a los modelos modulares en vehículos autónomos y robótica."
    ],
    "risks": [
      "La escasez de datos de alta calidad para post-entrenamiento limita la capacidad de optimización de los LLM actuales.",
      "La deriva acumulativa en rollouts de simuladores físicos latentes puede generar errores críticos en entornos reales.",
      "El tamaño masivo de los modelos MoE sigue superando la capacidad de memoria en dispositivos de borde (edge computing)."
    ],
    "watch": [
      "Capacidad de automejora de GPT-5.3 Codex y su impacto en la velocidad de desarrollo de software global.",
      "Adopción de servidores MCP por agentes de IA para automatizar el diseño y verificación de nuevos chips.",
      "Eficacia de la técnica KBVQ-MoE para comprimir modelos masivos a ultra-bajo bit sin pérdida de razonamiento."
    ],
    "entities_top": [
      "NVIDIA",
      "OpenAI",
      "TSMC"
    ]
  },
  "items": [
    {
      "title": "As AI Grows More Complex, Model Builders Rely on NVIDIA",
      "link": "https://blogs.nvidia.com/blog/leading-models-nvidia/",
      "published": "2025-12-11T19:19:57+00:00",
      "summary": "Unveiling what it describes as the most capable model series yet for professional knowledge work, OpenAI launched GPT-5.2 in December. The model was trained and deployed on NVIDIA infrastructure, including NVIDIA Hopper and GB200 NVL72 systems. GPT-5.3 Codex — the first OpenAI agentic coding model to help build itself — was released in February and\t<a class=\"read-more\" href=\"https://blogs.nvidia.com/blog/leading-models-nvidia/\">\n\t\tRead Article\t\t<span></span>\n\t</a>",
      "source": "NVIDIA Blog (AI)",
      "feed_tags": [
        "infra",
        "chips"
      ],
      "score": 98,
      "primary": "models",
      "tags": [
        "gpt-5",
        "agentes",
        "gb200"
      ],
      "_rid": 2,
      "why": "OpenAI revela modelos que ayudan a construirse a sí mismos ejecutados sobre la nueva arquitectura Blackwell.",
      "entities": [
        "OpenAI",
        "NVIDIA"
      ]
    },
    {
      "title": "NVIDIA Rubin Platform, Open Models, Autonomous Driving: NVIDIA Presents Blueprint for the Future at CES",
      "link": "https://blogs.nvidia.com/blog/2026-ces-special-presentation/",
      "published": "2026-01-05T23:30:18+00:00",
      "summary": "NVIDIA founder and CEO Jensen Huang took the stage at the Fontainebleau Las Vegas to open CES 2026, declaring that AI is scaling into every domain and every device. “Computing has been fundamentally reshaped as a result of accelerated computing, as a result of artificial intelligence,” Huang said. “What that means is some $10 trillion\t<a class=\"read-more\" href=\"https://blogs.nvidia.com/blog/2026-ces-special-presentation/\">\n\t\tRead Article\t\t<span></span>\n\t</a>",
      "source": "NVIDIA Blog (AI)",
      "feed_tags": [
        "infra",
        "chips"
      ],
      "score": 95,
      "primary": "infra",
      "tags": [
        "gpu",
        "rubin",
        "automotive",
        "scaling"
      ],
      "_rid": 18,
      "why": "NVIDIA presenta Rubin como sucesor de Blackwell, consolidando el dominio del hardware para el mercado de $10T.",
      "entities": [
        "NVIDIA",
        "Jensen Huang"
      ]
    },
    {
      "title": "TSMC vs Intel Foundry vs Samsung Foundry 2026",
      "link": "https://semiwiki.com/semiconductor-manufacturers/tsmc/366523-tsmc-vs-intel-foundry-vs-samsung-foundry-2026/",
      "published": "2026-02-13T14:00:18+00:00",
      "summary": "<p>The global semiconductor industry sits at the foundation of modern technology, powering everything from smartphones and cloud data centers to artificial intelligence, automobiles, and national defense systems. At the center of advanced chip manufacturing are three major players: <a href=\"https://semiwiki.com/category/semiconductor-manufacturers/tsmc/\"><strong>TSMC</strong></a>, <strong>Samsung Foundry</strong>, and <a href=\"https://semiwiki.com/category/semiconductor-manufacturers/intel/\"><strong>Intel Foundry</strong></a>&#8230; <a class=\"read-more\" href=\"https://semiwiki.com/semiconductor-manufacturers/tsmc/366523-tsmc-vs-intel-foundry-vs-samsung-foundry-2026/\">Read More </a></p>\n<p>The post <a href=\"https://semiwiki.com/semiconductor-manufacturers/tsmc/366523-tsmc-vs-intel-foundry-vs-samsung-foundry-2026/\">TSMC vs Intel Foundry vs Samsung Foundry 2026</a> appeared first on <a href=\"https://semiwiki.com\">SemiWiki</a>.</p>",
      "source": "SemiWiki",
      "feed_tags": [
        "infra",
        "chips"
      ],
      "score": 92,
      "primary": "infra",
      "tags": [
        "semiconductores",
        "foundry",
        "2nm"
      ],
      "_rid": 1,
      "why": "La hoja de ruta 2026 definirá el liderazgo en la fabricación de chips de IA de próxima generación.",
      "entities": [
        "TSMC",
        "Intel",
        "Samsung"
      ]
    },
    {
      "title": "Gemini 3 Deep Think: Advancing science, research and engineering",
      "link": "https://blog.google/innovation-and-ai/models-and-research/gemini-models/gemini-3-deep-think/",
      "published": "2026-02-12T16:13:00+00:00",
      "summary": "Gemini 3 Deep Think logo",
      "source": "Google AI Blog",
      "feed_tags": [
        "labs",
        "models"
      ],
      "score": 92,
      "primary": "models",
      "tags": [
        "reasoning",
        "science",
        "gemini-3"
      ],
      "_rid": 29,
      "why": "Gemini 3 Deep Think apunta a resolver problemas complejos en ciencia e ingeniería mediante razonamiento avanzado.",
      "entities": [
        "Google"
      ]
    },
    {
      "title": "Giving AI Agents Access to a Compiled Design and Verification Database",
      "link": "https://semiwiki.com/eda/amiq-eda/366471-giving-ai-agents-access-to-a-compiled-design-and-verification-database/",
      "published": "2026-02-12T16:00:40+00:00",
      "summary": "<p>A few weeks ago, I had the chance to work with AMIQ EDA as they <a href=\"https://www.einpresswire.com/article/886585001/amiq-eda-gives-ai-agents-access-to-essential-design-and-verification-data\">introduced</a> a new product: DVT MCP Server. I was quite intrigued by the role it will play in AI-assisted chip design and verification, so I wanted to learn more. I spoke with Gabriel Busuioc, the AI Assistant team leader at AMIQ EDA, to understand more about the product and how&#8230; <a class=\"read-more\" href=\"https://semiwiki.com/eda/amiq-eda/366471-giving-ai-agents-access-to-a-compiled-design-and-verification-database/\">Read More </a></p>\n<p>The post <a href=\"https://semiwiki.com/eda/amiq-eda/366471-giving-ai-agents-access-to-a-compiled-design-and-verification-database/\">Giving AI Agents Access to a Compiled Design and Verification Database</a> appeared first on <a href=\"https://semiwiki.com\">SemiWiki</a>.</p>",
      "source": "SemiWiki",
      "feed_tags": [
        "infra",
        "chips"
      ],
      "score": 90,
      "primary": "infra",
      "tags": [
        "eda",
        "chips",
        "agentes"
      ],
      "_rid": 13,
      "why": "Agentes de IA acceden directamente a bases de datos de diseño de chips, cerrando el ciclo de diseño automatizado.",
      "entities": [
        "AMIQ EDA"
      ]
    },
    {
      "title": "How Memory Technology Is Powering the Next Era of Compute",
      "link": "https://semiwiki.com/ip/rambus/366449-how-memory-technology-is-powering-the-next-era-of-compute/",
      "published": "2026-02-11T18:00:42+00:00",
      "summary": "<p>For more than a decade, progress in artificial intelligence has been framed almost entirely through the lens of compute. Faster GPUs, denser accelerators, and higher TOPS defined each new generation. But as generative and agentic AI enter their next phase, that framing is no longer sufficient. The most advanced AI systems today&#8230; <a class=\"read-more\" href=\"https://semiwiki.com/ip/rambus/366449-how-memory-technology-is-powering-the-next-era-of-compute/\">Read More </a></p>\n<p>The post <a href=\"https://semiwiki.com/ip/rambus/366449-how-memory-technology-is-powering-the-next-era-of-compute/\">How Memory Technology Is Powering the Next Era of Compute</a> appeared first on <a href=\"https://semiwiki.com\">SemiWiki</a>.</p>",
      "source": "SemiWiki",
      "feed_tags": [
        "infra",
        "chips"
      ],
      "score": 88,
      "primary": "infra",
      "tags": [
        "memoria",
        "hbm",
        "hardware"
      ],
      "_rid": 8,
      "why": "La memoria se identifica como el nuevo factor determinante para la evolución de la IA agente y generativa.",
      "entities": [
        "Rambus"
      ]
    },
    {
      "title": "NVIDIA Releases New AI Models and Developer Tools to Advance Autonomous Vehicle Ecosystem",
      "link": "https://blogs.nvidia.com/blog/autonomous-vehicle-ecosystem-ai-models-developer-tools/",
      "published": "2025-06-11T10:55:36+00:00",
      "summary": "Autonomous vehicle (AV) stacks are evolving from many distinct models to a unified, end-to-end architecture that executes driving actions directly from sensor data. This transition to using larger models is drastically increasing the demand for high-quality, physically based sensor data for training, testing and validation. To help accelerate the development of next-generation AV architectures, NVIDIA\t<a class=\"read-more\" href=\"https://blogs.nvidia.com/blog/autonomous-vehicle-ecosystem-ai-models-developer-tools/\">\n\t\tRead Article\t\t<span></span>\n\t</a>",
      "source": "NVIDIA Blog (AI)",
      "feed_tags": [
        "infra",
        "chips"
      ],
      "score": 85,
      "primary": "models",
      "tags": [
        "autónomos",
        "av",
        "sensores"
      ],
      "_rid": 12,
      "why": "Transición de arquitecturas AV hacia modelos end-to-end entrenados con datos basados en física.",
      "entities": [
        "NVIDIA"
      ]
    },
    {
      "title": "NVIDIA CEO Drops the Blueprint for Europe’s AI Boom",
      "link": "https://blogs.nvidia.com/blog/gtc-paris-2025/",
      "published": "2025-06-11T11:10:50+00:00",
      "summary": "At GTC Paris — held alongside VivaTech, Europe’s largest tech event — NVIDIA founder and CEO Jensen Huang delivered a clear message: Europe isn’t just adopting AI — it’s building it. “We now have a new industry, an AI industry, and it’s now part of the new infrastructure, called intelligence infrastructure, that will be used\t<a class=\"read-more\" href=\"https://blogs.nvidia.com/blog/gtc-paris-2025/\">\n\t\tRead Article\t\t<span></span>\n\t</a>",
      "source": "NVIDIA Blog (AI)",
      "feed_tags": [
        "infra",
        "chips"
      ],
      "score": 85,
      "primary": "geopol",
      "tags": [
        "sovereign-ai",
        "europe",
        "infrastructure"
      ],
      "_rid": 24,
      "why": "NVIDIA impulsa la soberanía tecnológica en Europa mediante la creación de infraestructura de inteligencia local.",
      "entities": [
        "NVIDIA",
        "Jensen Huang"
      ]
    },
    {
      "title": "NVIDIA Research Shapes Physical AI",
      "link": "https://blogs.nvidia.com/blog/physical-ai-research-siggraph-2025/",
      "published": "2025-08-11T15:00:38+00:00",
      "summary": "AI and graphics research breakthroughs in neural rendering, 3D generation and world simulation power robotics, autonomous vehicles and content creation.",
      "source": "NVIDIA Blog (AI)",
      "feed_tags": [
        "infra",
        "chips"
      ],
      "score": 82,
      "primary": "models",
      "tags": [
        "physical-ai",
        "robótica",
        "simulación"
      ],
      "_rid": 3,
      "why": "Avances en renderizado neural y simulación de mundo aceleran la autonomía física de los sistemas de IA.",
      "entities": [
        "NVIDIA"
      ]
    },
    {
      "title": "Latent Generative Solvers for Generalizable Long-Term Physics Simulation",
      "link": "https://arxiv.org/abs/2602.11229",
      "published": "2026-02-13T05:00:00+00:00",
      "summary": "arXiv:2602.11229v1 Announce Type: new \nAbstract: We study long-horizon surrogate simulation across heterogeneous PDE systems. We introduce Latent Generative Solvers (LGS), a two-stage framework that (i) maps diverse PDE states into a shared latent physics space with a pretrained VAE, and (ii) learns probabilistic latent dynamics with a Transformer trained by flow matching. Our key mechanism is an uncertainty knob that perturbs latent inputs during training and inference, teaching the solver to correct off-manifold rollout drift and stabilizing autoregressive prediction. We further use flow forcing to update a system descriptor (context) from model-generated trajectories, aligning train/test conditioning and improving long-term stability. We pretrain on a curated corpus of $\\sim$2.5M trajectories at $128^2$ resolution spanning 12 PDE families. LGS matches strong deterministic neural-operator baselines on short horizons while substantially reducing rollout drift on long horizons. Learning in latent space plus efficient architectural choices yields up to \\textbf{70$\\times$} lower FLOPs than non-generative baselines, enabling scalable pretraining. We also show efficient adaptation to an out-of-distribution $256^2$ Kolmogorov flow dataset under limited finetuning budgets. Overall, LGS provides a practical route toward generalizable, uncertainty-aware neural PDE solvers that are more reliable for long-term forecasting and downstream scientific workflows.",
      "source": "arXiv cs.AI",
      "feed_tags": [
        "papers",
        "models"
      ],
      "score": 78,
      "primary": "models",
      "tags": [
        "física",
        "simulación",
        "pde"
      ],
      "_rid": 6,
      "why": "Nuevo framework LGS utiliza VAE y Transformers para simulaciones físicas estables de largo plazo.",
      "entities": []
    },
    {
      "title": "Hear more about interactive world models in our latest podcast.",
      "link": "https://blog.google/innovation-and-ai/technology/ai/release-notes-podcast-project-genie/",
      "published": "2026-01-29T15:00:00+00:00",
      "summary": "Project Genie: Create and explore worlds",
      "source": "Google AI Blog",
      "feed_tags": [
        "labs",
        "models"
      ],
      "score": 78,
      "primary": "models",
      "tags": [
        "world-models",
        "gaming",
        "gen-ai"
      ],
      "_rid": 17,
      "why": "Project Genie permite crear entornos virtuales interactivos a partir de descripciones, clave para entrenamiento de agentes.",
      "entities": [
        "Google DeepMind"
      ]
    },
    {
      "title": "Project Genie: Experimenting with infinite, interactive worlds",
      "link": "https://blog.google/innovation-and-ai/models-and-research/google-deepmind/project-genie/",
      "published": "2026-01-29T17:00:00+00:00",
      "summary": "Text reads Introducing Project Genie",
      "source": "Google AI Blog",
      "feed_tags": [
        "labs",
        "models"
      ],
      "score": 77,
      "primary": "models",
      "tags": [
        "simulation",
        "world-models",
        "video-gen"
      ],
      "_rid": 23,
      "why": "Desarrollo de mundos infinitos e interactivos mediante modelos fundacionales de video y acción.",
      "entities": [
        "Google DeepMind"
      ]
    },
    {
      "title": "KBVQ-MoE: KLT-guided SVD with Bias-Corrected Vector Quantization for MoE Large Language Models",
      "link": "https://arxiv.org/abs/2602.11184",
      "published": "2026-02-13T05:00:00+00:00",
      "summary": "arXiv:2602.11184v1 Announce Type: new \nAbstract: Mixture of Experts (MoE) models have achieved great success by significantly improving performance while maintaining computational efficiency through sparse expert activation. However, their enormous parameter sizes and memory demands pose major challenges for deployment in resource-constrained environments. Vector Quantization (VQ) offers a promising approach for ultra-low-bit compression in Large Language Models (LLMs) by leveraging a codebook, where weight vectors are mapped to the most similar discrete codewords. Yet, directly applying VQ to MoEs often leads to substantial performance degradation due to two critical obstacles: (1) redundant representations among experts cause VQ to repeatedly quantize similar representations for each expert, resulting in inefficient use of limited codebook capacity; and (2) cumulative output bias is amplified by expert aggregation in MoE layers, leading to distributional shifts in the quantized outputs. To address these issues, we propose KBVQ-MoE, a novel VQ framework to enhance extremely low-bit quantization for MoE-based LLMs. KBVQ-MoE integrates two techniques: (1) input-driven redundancy elimination, where a Karhunen-Loeve Transform (KLT) guided singular value decomposition (SVD) extracts dominant weight components and shares them across experts; and (2) bias-corrected output stabilization, where vector quantization is applied only to expert-specific (non-redundant) representations and the quantized outputs are corrected via channel-wise affine compensation. Experiments on various MoE LLMs demonstrate that KBVQ-MoE preserves accuracy substantially better than existing quantization methods. For example, 3-bit quantization of Qwen1.5-MoE-A2.7B achieves an average accuracy of 67.99, nearly identical to the FP16 baseline of 68.07, underscoring KBVQ-MoE's potential for efficient deployment on edge devices and other resource-constrained platforms.",
      "source": "arXiv cs.LG",
      "feed_tags": [
        "papers",
        "models"
      ],
      "score": 75,
      "primary": "models",
      "tags": [
        "moe",
        "compresión",
        "cuantización"
      ],
      "_rid": 7,
      "why": "Técnica KBVQ-MoE permite desplegar modelos masivos en hardware limitado mediante compresión de ultra-bajo bit.",
      "entities": []
    },
    {
      "title": "Isambard-AI, the UK’s Most Powerful AI Supercomputer, Goes Live",
      "link": "https://blogs.nvidia.com/blog/isambard-ai/",
      "published": "2025-07-17T17:00:50+00:00",
      "summary": "The University of Bristol’s Isambard-AI, powered by NVIDIA Grace Hopper Superchips, delivers 21 exaflops of AI performance, making it the fastest system in the U.K. and among the most energy-efficient globally.",
      "source": "NVIDIA Blog (AI)",
      "feed_tags": [
        "infra",
        "chips"
      ],
      "score": 74,
      "primary": "infra",
      "tags": [
        "supercomputación",
        "hpc",
        "uk"
      ],
      "_rid": 9,
      "why": "Isambard-AI alcanza 21 exaflops, posicionando al Reino Unido en la élite de infraestructura para IA.",
      "entities": [
        "NVIDIA",
        "University of Bristol"
      ]
    },
    {
      "title": "Silicon Catalyst at the Chiplet Summit: Advancing the Chiplet Economy",
      "link": "https://semiwiki.com/semiconductor-services/silicon-catalyst/366270-silicon-catalyst-at-the-chiplet-summit-advancing-the-chiplet-economy/",
      "published": "2026-02-12T18:00:04+00:00",
      "summary": "<p>\n<p>The rapid evolution of semiconductor design has elevated <a href=\"https://semiwiki.com/category/chiplet/\">chiplets</a> from a niche concept to a foundational strategy for next-generation computing. At the upcoming <a href=\"https://chipletsummit.com/\">Chiplet Summit</a> &#8211; February 17–19, 2026 Santa Clara Convention Center. Silicon Catalyst will play a central role in shaping this conversation, highlighting&#8230; <a class=\"read-more\" href=\"https://semiwiki.com/semiconductor-services/silicon-catalyst/366270-silicon-catalyst-at-the-chiplet-summit-advancing-the-chiplet-economy/\">Read More </a></p>\n<p>The post <a href=\"https://semiwiki.com/semiconductor-services/silicon-catalyst/366270-silicon-catalyst-at-the-chiplet-summit-advancing-the-chiplet-economy/\">Silicon Catalyst at the Chiplet Summit: Advancing the Chiplet Economy</a> appeared first on <a href=\"https://semiwiki.com\">SemiWiki</a>.</p>",
      "source": "SemiWiki",
      "feed_tags": [
        "infra",
        "chips"
      ],
      "score": 72,
      "primary": "infra",
      "tags": [
        "chiplets",
        "semiconductors",
        "efficiency"
      ],
      "_rid": 19,
      "why": "La economía del chiplet se consolida como el estándar para mantener la ley de Moore en procesadores de IA complejos.",
      "entities": [
        "Silicon Catalyst",
        "Chiplet Summit"
      ]
    }
  ]
}