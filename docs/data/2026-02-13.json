{
  "date": "2026-02-13",
  "score_avg": 82.33,
  "primary_dist": {
    "models": 4,
    "infra": 8,
    "invest": 1,
    "geopol": 2
  },
  "top_entities": [
    {
      "entity": "NVIDIA",
      "count": 8
    },
    {
      "entity": "Jensen Huang",
      "count": 2
    },
    {
      "entity": "OpenAI",
      "count": 1
    },
    {
      "entity": "TSMC",
      "count": 1
    },
    {
      "entity": "Intel",
      "count": 1
    }
  ],
  "briefing": {
    "signals": [
      "GPT-5.2 ya opera sobre infraestructura Hopper/Blackwell confirmando el ciclo de renovacion de hardware acelerado.",
      "La soberania de la IA se materializa con supercomputadores regionales como Isambard-AI y modelos linguisticos locales.",
      "El diseño de chips se automatiza mediante agentes de IA y acceso a bases de datos de verificacion especializadas.",
      "La tecnologia de memoria se posiciona como el factor critico de rendimiento por encima de la potencia de computo pura.",
      "La convergencia de IA y fisica mediante simuladores latentes permite modelado complejo en ingenieria y robotica."
    ],
    "risks": [
      "Cuello de botella critico en el ancho de banda de memoria para sostener el crecimiento de modelos agenticos.",
      "Degradacion del rendimiento en modelos MoE al aplicar tecnicas de compresion para despliegue en el edge.",
      "Escasez de datos de alta calidad para el entrenamiento de modelos de optimizacion matematica compleja."
    ],
    "watch": [
      "Lanzamiento comercial de GPT-5.3 Codex y su capacidad real de auto-mejora de codigo.",
      "Competencia de nodos de 2nm entre TSMC, Intel y Samsung prevista para el cierre de 2026.",
      "Adopcion de arquitecturas end-to-end unificadas en el ecosistema de vehiculos autonomos."
    ],
    "entities_top": [
      "NVIDIA",
      "OpenAI",
      "TSMC"
    ]
  },
  "items": [
    {
      "title": "As AI Grows More Complex, Model Builders Rely on NVIDIA",
      "link": "https://blogs.nvidia.com/blog/leading-models-nvidia/",
      "published": "2025-12-11T19:19:57+00:00",
      "summary": "Unveiling what it describes as the most capable model series yet for professional knowledge work, OpenAI launched GPT-5.2 in December. The model was trained and deployed on NVIDIA infrastructure, including NVIDIA Hopper and GB200 NVL72 systems. GPT-5.3 Codex — the first OpenAI agentic coding model to help build itself — was released in February and\t<a class=\"read-more\" href=\"https://blogs.nvidia.com/blog/leading-models-nvidia/\">\n\t\tRead Article\t\t<span></span>\n\t</a>",
      "source": "NVIDIA Blog (AI)",
      "feed_tags": [
        "infra",
        "chips"
      ],
      "score": 95,
      "primary": "models",
      "tags": [
        "gpt-5",
        "hopper",
        "agents",
        "blackwell"
      ],
      "_rid": 2,
      "why": "Confirmacion de GPT-5.2 en infraestructura NVIDIA y la llegada de agentes que participan en su propia construccion.",
      "entities": [
        "OpenAI",
        "NVIDIA"
      ]
    },
    {
      "title": "NVIDIA Rubin Platform, Open Models, Autonomous Driving: NVIDIA Presents Blueprint for the Future at CES",
      "link": "https://blogs.nvidia.com/blog/2026-ces-special-presentation/",
      "published": "2026-01-05T23:30:18+00:00",
      "summary": "NVIDIA founder and CEO Jensen Huang took the stage at the Fontainebleau Las Vegas to open CES 2026, declaring that AI is scaling into every domain and every device. “Computing has been fundamentally reshaped as a result of accelerated computing, as a result of artificial intelligence,” Huang said. “What that means is some $10 trillion\t<a class=\"read-more\" href=\"https://blogs.nvidia.com/blog/2026-ces-special-presentation/\">\n\t\tRead Article\t\t<span></span>\n\t</a>",
      "source": "NVIDIA Blog (AI)",
      "feed_tags": [
        "infra",
        "chips"
      ],
      "score": 95,
      "primary": "infra",
      "tags": [
        "gpu",
        "rubin",
        "roadmap"
      ],
      "_rid": 18,
      "why": "El anuncio de la plataforma Rubin define el futuro del hardware de IA y la continuidad del dominio de NVIDIA.",
      "entities": [
        "NVIDIA",
        "Jensen Huang"
      ]
    },
    {
      "title": "TSMC vs Intel Foundry vs Samsung Foundry 2026",
      "link": "https://semiwiki.com/semiconductor-manufacturers/tsmc/366523-tsmc-vs-intel-foundry-vs-samsung-foundry-2026/",
      "published": "2026-02-13T14:00:18+00:00",
      "summary": "<p>The global semiconductor industry sits at the foundation of modern technology, powering everything from smartphones and cloud data centers to artificial intelligence, automobiles, and national defense systems. At the center of advanced chip manufacturing are three major players: <a href=\"https://semiwiki.com/category/semiconductor-manufacturers/tsmc/\"><strong>TSMC</strong></a>, <strong>Samsung Foundry</strong>, and <a href=\"https://semiwiki.com/category/semiconductor-manufacturers/intel/\"><strong>Intel Foundry</strong></a>&#8230; <a class=\"read-more\" href=\"https://semiwiki.com/semiconductor-manufacturers/tsmc/366523-tsmc-vs-intel-foundry-vs-samsung-foundry-2026/\">Read More </a></p>\n<p>The post <a href=\"https://semiwiki.com/semiconductor-manufacturers/tsmc/366523-tsmc-vs-intel-foundry-vs-samsung-foundry-2026/\">TSMC vs Intel Foundry vs Samsung Foundry 2026</a> appeared first on <a href=\"https://semiwiki.com\">SemiWiki</a>.</p>",
      "source": "SemiWiki",
      "feed_tags": [
        "infra",
        "chips"
      ],
      "score": 92,
      "primary": "infra",
      "tags": [
        "foundry",
        "nodes",
        "2nm",
        "semiconductors"
      ],
      "_rid": 1,
      "why": "La competencia por los nodos de 2nm definira la capacidad de escalado y eficiencia de la IA global hacia 2026.",
      "entities": [
        "TSMC",
        "Intel",
        "Samsung"
      ]
    },
    {
      "title": "How Memory Technology Is Powering the Next Era of Compute",
      "link": "https://semiwiki.com/ip/rambus/366449-how-memory-technology-is-powering-the-next-era-of-compute/",
      "published": "2026-02-11T18:00:42+00:00",
      "summary": "<p>For more than a decade, progress in artificial intelligence has been framed almost entirely through the lens of compute. Faster GPUs, denser accelerators, and higher TOPS defined each new generation. But as generative and agentic AI enter their next phase, that framing is no longer sufficient. The most advanced AI systems today&#8230; <a class=\"read-more\" href=\"https://semiwiki.com/ip/rambus/366449-how-memory-technology-is-powering-the-next-era-of-compute/\">Read More </a></p>\n<p>The post <a href=\"https://semiwiki.com/ip/rambus/366449-how-memory-technology-is-powering-the-next-era-of-compute/\">How Memory Technology Is Powering the Next Era of Compute</a> appeared first on <a href=\"https://semiwiki.com\">SemiWiki</a>.</p>",
      "source": "SemiWiki",
      "feed_tags": [
        "infra",
        "chips"
      ],
      "score": 88,
      "primary": "infra",
      "tags": [
        "hbm",
        "memory-wall",
        "bandwidth",
        "rambus"
      ],
      "_rid": 8,
      "why": "El limite de rendimiento de la IA se desplaza del computo puro hacia el ancho de banda de la memoria.",
      "entities": [
        "Rambus"
      ]
    },
    {
      "title": "Gemini 3 Deep Think: Advancing science, research and engineering",
      "link": "https://blog.google/innovation-and-ai/models-and-research/gemini-models/gemini-3-deep-think/",
      "published": "2026-02-12T16:13:00+00:00",
      "summary": "Gemini 3 Deep Think logo",
      "source": "Google AI Blog",
      "feed_tags": [
        "labs",
        "models"
      ],
      "score": 88,
      "primary": "models",
      "tags": [
        "reasoning",
        "science",
        "gemini"
      ],
      "_rid": 29,
      "why": "Gemini 3 Deep Think prioriza el razonamiento complejo, compitiendo en el segmento de modelos para ciencia.",
      "entities": [
        "Google"
      ]
    },
    {
      "title": "Isambard-AI, the UK’s Most Powerful AI Supercomputer, Goes Live",
      "link": "https://blogs.nvidia.com/blog/isambard-ai/",
      "published": "2025-07-17T17:00:50+00:00",
      "summary": "The University of Bristol’s Isambard-AI, powered by NVIDIA Grace Hopper Superchips, delivers 21 exaflops of AI performance, making it the fastest system in the U.K. and among the most energy-efficient globally.",
      "source": "NVIDIA Blog (AI)",
      "feed_tags": [
        "infra",
        "chips"
      ],
      "score": 86,
      "primary": "infra",
      "tags": [
        "supercomputer",
        "grace-hopper",
        "uk",
        "exaflops"
      ],
      "_rid": 9,
      "why": "Activacion de 21 exaflops de rendimiento para investigacion soberana en el Reino Unido.",
      "entities": [
        "NVIDIA",
        "University of Bristol"
      ]
    },
    {
      "title": "KBVQ-MoE: KLT-guided SVD with Bias-Corrected Vector Quantization for MoE Large Language Models",
      "link": "https://arxiv.org/abs/2602.11184",
      "published": "2026-02-13T05:00:00+00:00",
      "summary": "arXiv:2602.11184v1 Announce Type: new \nAbstract: Mixture of Experts (MoE) models have achieved great success by significantly improving performance while maintaining computational efficiency through sparse expert activation. However, their enormous parameter sizes and memory demands pose major challenges for deployment in resource-constrained environments. Vector Quantization (VQ) offers a promising approach for ultra-low-bit compression in Large Language Models (LLMs) by leveraging a codebook, where weight vectors are mapped to the most similar discrete codewords. Yet, directly applying VQ to MoEs often leads to substantial performance degradation due to two critical obstacles: (1) redundant representations among experts cause VQ to repeatedly quantize similar representations for each expert, resulting in inefficient use of limited codebook capacity; and (2) cumulative output bias is amplified by expert aggregation in MoE layers, leading to distributional shifts in the quantized outputs. To address these issues, we propose KBVQ-MoE, a novel VQ framework to enhance extremely low-bit quantization for MoE-based LLMs. KBVQ-MoE integrates two techniques: (1) input-driven redundancy elimination, where a Karhunen-Loeve Transform (KLT) guided singular value decomposition (SVD) extracts dominant weight components and shares them across experts; and (2) bias-corrected output stabilization, where vector quantization is applied only to expert-specific (non-redundant) representations and the quantized outputs are corrected via channel-wise affine compensation. Experiments on various MoE LLMs demonstrate that KBVQ-MoE preserves accuracy substantially better than existing quantization methods. For example, 3-bit quantization of Qwen1.5-MoE-A2.7B achieves an average accuracy of 67.99, nearly identical to the FP16 baseline of 68.07, underscoring KBVQ-MoE's potential for efficient deployment on edge devices and other resource-constrained platforms.",
      "source": "arXiv cs.LG",
      "feed_tags": [
        "papers",
        "models"
      ],
      "score": 84,
      "primary": "infra",
      "tags": [
        "compression",
        "moe",
        "quantization",
        "memory"
      ],
      "_rid": 7,
      "why": "Nueva tecnica de compresion para modelos MoE que facilita su despliegue en hardware con memoria limitada.",
      "entities": []
    },
    {
      "title": "NVIDIA Research Shapes Physical AI",
      "link": "https://blogs.nvidia.com/blog/physical-ai-research-siggraph-2025/",
      "published": "2025-08-11T15:00:38+00:00",
      "summary": "AI and graphics research breakthroughs in neural rendering, 3D generation and world simulation power robotics, autonomous vehicles and content creation.",
      "source": "NVIDIA Blog (AI)",
      "feed_tags": [
        "infra",
        "chips"
      ],
      "score": 82,
      "primary": "models",
      "tags": [
        "robotics",
        "simulation",
        "3d",
        "physical-ai"
      ],
      "_rid": 3,
      "why": "Avances en renderizado neural y simulacion de mundos para acelerar la autonomia fisica de la IA.",
      "entities": [
        "NVIDIA"
      ]
    },
    {
      "title": "NVIDIA Releases New AI Models and Developer Tools to Advance Autonomous Vehicle Ecosystem",
      "link": "https://blogs.nvidia.com/blog/autonomous-vehicle-ecosystem-ai-models-developer-tools/",
      "published": "2025-06-11T10:55:36+00:00",
      "summary": "Autonomous vehicle (AV) stacks are evolving from many distinct models to a unified, end-to-end architecture that executes driving actions directly from sensor data. This transition to using larger models is drastically increasing the demand for high-quality, physically based sensor data for training, testing and validation. To help accelerate the development of next-generation AV architectures, NVIDIA\t<a class=\"read-more\" href=\"https://blogs.nvidia.com/blog/autonomous-vehicle-ecosystem-ai-models-developer-tools/\">\n\t\tRead Article\t\t<span></span>\n\t</a>",
      "source": "NVIDIA Blog (AI)",
      "feed_tags": [
        "infra",
        "chips"
      ],
      "score": 80,
      "primary": "infra",
      "tags": [
        "autonomous-vehicles",
        "simulation",
        "sensors"
      ],
      "_rid": 12,
      "why": "Transicion hacia arquitecturas unificadas end-to-end que ejecutan acciones directamente desde datos de sensores.",
      "entities": [
        "NVIDIA"
      ]
    },
    {
      "title": "Latent Generative Solvers for Generalizable Long-Term Physics Simulation",
      "link": "https://arxiv.org/abs/2602.11229",
      "published": "2026-02-13T05:00:00+00:00",
      "summary": "arXiv:2602.11229v1 Announce Type: new \nAbstract: We study long-horizon surrogate simulation across heterogeneous PDE systems. We introduce Latent Generative Solvers (LGS), a two-stage framework that (i) maps diverse PDE states into a shared latent physics space with a pretrained VAE, and (ii) learns probabilistic latent dynamics with a Transformer trained by flow matching. Our key mechanism is an uncertainty knob that perturbs latent inputs during training and inference, teaching the solver to correct off-manifold rollout drift and stabilizing autoregressive prediction. We further use flow forcing to update a system descriptor (context) from model-generated trajectories, aligning train/test conditioning and improving long-term stability. We pretrain on a curated corpus of $\\sim$2.5M trajectories at $128^2$ resolution spanning 12 PDE families. LGS matches strong deterministic neural-operator baselines on short horizons while substantially reducing rollout drift on long horizons. Learning in latent space plus efficient architectural choices yields up to \\textbf{70$\\times$} lower FLOPs than non-generative baselines, enabling scalable pretraining. We also show efficient adaptation to an out-of-distribution $256^2$ Kolmogorov flow dataset under limited finetuning budgets. Overall, LGS provides a practical route toward generalizable, uncertainty-aware neural PDE solvers that are more reliable for long-term forecasting and downstream scientific workflows.",
      "source": "arXiv cs.AI",
      "feed_tags": [
        "papers",
        "models"
      ],
      "score": 78,
      "primary": "models",
      "tags": [
        "pde",
        "physics",
        "simulation",
        "latent-space"
      ],
      "_rid": 6,
      "why": "Simulacion de fisica compleja a largo plazo mediante espacios latentes, fundamental para diseño industrial.",
      "entities": []
    },
    {
      "title": "Silicon Catalyst at the Chiplet Summit: Advancing the Chiplet Economy",
      "link": "https://semiwiki.com/semiconductor-services/silicon-catalyst/366270-silicon-catalyst-at-the-chiplet-summit-advancing-the-chiplet-economy/",
      "published": "2026-02-12T18:00:04+00:00",
      "summary": "<p>\n<p>The rapid evolution of semiconductor design has elevated <a href=\"https://semiwiki.com/category/chiplet/\">chiplets</a> from a niche concept to a foundational strategy for next-generation computing. At the upcoming <a href=\"https://chipletsummit.com/\">Chiplet Summit</a> &#8211; February 17–19, 2026 Santa Clara Convention Center. Silicon Catalyst will play a central role in shaping this conversation, highlighting&#8230; <a class=\"read-more\" href=\"https://semiwiki.com/semiconductor-services/silicon-catalyst/366270-silicon-catalyst-at-the-chiplet-summit-advancing-the-chiplet-economy/\">Read More </a></p>\n<p>The post <a href=\"https://semiwiki.com/semiconductor-services/silicon-catalyst/366270-silicon-catalyst-at-the-chiplet-summit-advancing-the-chiplet-economy/\">Silicon Catalyst at the Chiplet Summit: Advancing the Chiplet Economy</a> appeared first on <a href=\"https://semiwiki.com\">SemiWiki</a>.</p>",
      "source": "SemiWiki",
      "feed_tags": [
        "infra",
        "chips"
      ],
      "score": 78,
      "primary": "infra",
      "tags": [
        "chiplets",
        "semiconductors",
        "packaging"
      ],
      "_rid": 19,
      "why": "La transición a chiplets es fundamental para superar los límites físicos de los diseños monolíticos en IA.",
      "entities": [
        "Silicon Catalyst"
      ]
    },
    {
      "title": "Giving AI Agents Access to a Compiled Design and Verification Database",
      "link": "https://semiwiki.com/eda/amiq-eda/366471-giving-ai-agents-access-to-a-compiled-design-and-verification-database/",
      "published": "2026-02-12T16:00:40+00:00",
      "summary": "<p>A few weeks ago, I had the chance to work with AMIQ EDA as they <a href=\"https://www.einpresswire.com/article/886585001/amiq-eda-gives-ai-agents-access-to-essential-design-and-verification-data\">introduced</a> a new product: DVT MCP Server. I was quite intrigued by the role it will play in AI-assisted chip design and verification, so I wanted to learn more. I spoke with Gabriel Busuioc, the AI Assistant team leader at AMIQ EDA, to understand more about the product and how&#8230; <a class=\"read-more\" href=\"https://semiwiki.com/eda/amiq-eda/366471-giving-ai-agents-access-to-a-compiled-design-and-verification-database/\">Read More </a></p>\n<p>The post <a href=\"https://semiwiki.com/eda/amiq-eda/366471-giving-ai-agents-access-to-a-compiled-design-and-verification-database/\">Giving AI Agents Access to a Compiled Design and Verification Database</a> appeared first on <a href=\"https://semiwiki.com\">SemiWiki</a>.</p>",
      "source": "SemiWiki",
      "feed_tags": [
        "infra",
        "chips"
      ],
      "score": 75,
      "primary": "infra",
      "tags": [
        "eda",
        "chip-design",
        "agents",
        "verification"
      ],
      "_rid": 13,
      "why": "Uso de agentes de IA para acelerar la verificacion y diseño de semiconductores mediante bases de datos compiladas.",
      "entities": [
        "AMIQ EDA"
      ]
    },
    {
      "title": "Innovation to Impact: How NVIDIA Research Fuels Transformative Work in AI, Graphics and Beyond",
      "link": "https://blogs.nvidia.com/blog/nvidia-research-ai-graphics/",
      "published": "2025-03-20T00:00:24+00:00",
      "summary": "The roots of many of NVIDIA’s landmark innovations — the foundational technology that powers AI, accelerated computing, real-time ray tracing and seamlessly connected data centers — can be found in the company’s research organization, a global team of around 400 experts in fields including computer architecture, generative AI, graphics and robotics. Established in 2006 and\t<a class=\"read-more\" href=\"https://blogs.nvidia.com/blog/nvidia-research-ai-graphics/\">\n\t\tRead Article\t\t<span></span>\n\t</a>",
      "source": "NVIDIA Blog (AI)",
      "feed_tags": [
        "infra",
        "chips"
      ],
      "score": 72,
      "primary": "invest",
      "tags": [
        "r&d",
        "graphics",
        "ray-tracing"
      ],
      "_rid": 10,
      "why": "La investigacion interna de NVIDIA sigue siendo el motor que anticipa sus ciclos de producto y dominio de mercado.",
      "entities": [
        "NVIDIA"
      ]
    },
    {
      "title": "NVIDIA CEO Drops the Blueprint for Europe’s AI Boom",
      "link": "https://blogs.nvidia.com/blog/gtc-paris-2025/",
      "published": "2025-06-11T11:10:50+00:00",
      "summary": "At GTC Paris — held alongside VivaTech, Europe’s largest tech event — NVIDIA founder and CEO Jensen Huang delivered a clear message: Europe isn’t just adopting AI — it’s building it. “We now have a new industry, an AI industry, and it’s now part of the new infrastructure, called intelligence infrastructure, that will be used\t<a class=\"read-more\" href=\"https://blogs.nvidia.com/blog/gtc-paris-2025/\">\n\t\tRead Article\t\t<span></span>\n\t</a>",
      "source": "NVIDIA Blog (AI)",
      "feed_tags": [
        "infra",
        "chips"
      ],
      "score": 72,
      "primary": "geopol",
      "tags": [
        "europe",
        "sovereign ai",
        "infrastructure"
      ],
      "_rid": 24,
      "why": "NVIDIA refuerza su posición en Europa como proveedor base para la infraestructura de inteligencia soberana.",
      "entities": [
        "NVIDIA",
        "Jensen Huang"
      ]
    },
    {
      "title": "Reaching Across the Isles: UK-LLM Brings AI to UK Languages With NVIDIA Nemotron",
      "link": "https://blogs.nvidia.com/blog/uk-llm-nemotron/",
      "published": "2025-09-14T01:00:21+00:00",
      "summary": "Celtic languages — including Cornish, Irish, Scottish Gaelic and Welsh — are the U.K.’s oldest living languages. To empower their speakers, the UK-LLM sovereign AI initiative is building an AI model based on NVIDIA Nemotron that can reason in both English and Welsh, a language spoken by about 850,000 people in Wales today. Enabling high-quality\t<a class=\"read-more\" href=\"https://blogs.nvidia.com/blog/uk-llm-nemotron/\">\n\t\tRead Article\t\t<span></span>\n\t</a>",
      "source": "NVIDIA Blog (AI)",
      "feed_tags": [
        "infra",
        "chips"
      ],
      "score": 70,
      "primary": "geopol",
      "tags": [
        "sovereign-ai",
        "nemotron",
        "uk",
        "languages"
      ],
      "_rid": 5,
      "why": "Despliegue de IA soberana para lenguajes minoritarios britanicos utilizando la base de Nemotron.",
      "entities": [
        "NVIDIA"
      ]
    }
  ]
}